---
layout: notes
title: "üìì3.2: Impact of Program Design" 
parent: "3Ô∏è‚É£ Class Creation"
nav_order: 2
---

## Table of Contents
{: .no_toc .text-delta }

{: .fs-2 }
- TOC
{:toc}

---

{:.note}
üìñ This page is a condensed version of [CSAwesome Topic 3.2](https://runestone.academy/ns/books/published/csawesome2/topic-3-2-impacts.html) 

---

## Impact of Program Design

We are living in an age of rapid development in technology and automation. Software and hardware developers increasingly have real **impacts** on people's lives. In computer science, we follow the following [ACM Professional Code of Ethics](https://ethics.acm.org/) which includes guidelines such as _"avoid harm"_ and _"respect privacy"_.
> However, sometimes programs have _unintended consequences_. It can be difficult to ensure **system reliability**, which refers to a program being able to perform its tasks as expected under stated conditions without failure. Programmers should make an effort to maximize system reliability by **testing** the program with a variety of conditions.

{:.highlight}
The creation of programs has **impacts** on _society_, the _economy_, and _culture_. These impacts can be both beneficial and harmful. Programs meant to fill a need or solve a problem can have _unintended harmful effects_ beyond their intended use.

‚öñÔ∏è **Legal issues** and intellectual property (IP) concerns can also arise when creating programs. Programmers often _reuse_ code written by others and published as **open source** which is free to use. Incorporation of code that is _not_ published as open source requires the programmer to obtain **permission** and often purchase the code before integrating it into their program. There are also newly arising issues with the use of generative AI in coding.

üß† The fields of **AI (Artificial Intelligence)** and **Machine Learning** increasingly pose ethical questions in our world. For example, self-driving cars that use machine learning to learn to follow lanes and avoid collisions could make our world much safer. Self-driving cars do not get distracted by text messages and don't drink and drive. However, what if the car needs to make an **ethical decision** about avoiding a collision with a pedestrian by causing an accident that may also lead to the loss of life? _Who makes these decisions?_ The software? the programmers? If you were a programmer for a self-driving car, how would you approach such decisions? 

Watch the following video to explore the ethical challenge of self-driving cars:

<iframe width="560" height="315" src="https://www.youtube.com/embed/ixIoDYVfKA0?si=q62KFv-lYsw-IGVQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

Here are some other interesting videos about the impacts of AI in different domains:

- AI in Healthcare: [Using artificial intelligence in radiology clinical practice](https://www.youtube.com/watch?v=dCDuMyzWS8Q)
- AI in Agriculture: [New farm machines to kill weeds and harvest crops](https://www.youtube.com/watch?v=DjHGG7eQevY)

<div class="task" markdown="block">

In groups, choose a **software application** that has social and ethical implications. 
> If you chose an AI application, make sure you narrow it to a particular domain or use.

üí¨ **DISCUSS:**
* the **beneficial** and possible **harmful** effects of this software application
* the **ethical issues** that may arise and how programmers can try to avoid them

Prepare a short presentation for your class.

</div>

### Technology is NOT Neutral

Historian [Melvin Kranzberg](https://en.wikipedia.org/wiki/Melvin_Kranzberg)‚Äôs famous first law of technology argues that ‚Äútechnology is neither good nor bad; _nor is it neutral._‚Äù

> Also see the presentation ["Technology is Not Neutral" by Stephanie Hare, PhD](https://indico.cern.ch/event/1214023/attachments/2556457/4405409/Hare_CERN%20_28-29Nov2022.pdf)

{: .highlight }
"As we‚Äôre designing the system, we‚Äôre designing society. Ethical rules that we choose to put into that design [impact society]‚Ä¶ Nothing is self-evident. Everything has to be put out there as something that we think will be a good idea as a component of our society" - **Sir Tim Berners-Lee**, Creator of the World Wide Web

<iframe width="560" height="315" src="https://www.youtube.com/embed/ixIoDYVfKA0?si=q62KFv-lYsw-IGVQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

---

## ‚≠êÔ∏è Summary

- (AP 3.2.A.1) **System reliability** refers to the program being able to perform its tasks as expected under stated conditions without failure. Programmers should make an effort to maximize system reliability by testing the program with a variety of conditions.

- (AP 3.2.A.2) The creation of programs has impacts on society, the economy, and culture. These impacts can be both beneficial and harmful. Programs meant to fill a need or solve a problem can have unintended harmful effects beyond their intended use.

- (AP 3.1.A.3) Legal issues and intellectual property concerns arise when creating programs. Programmers often reuse code written by others and published as **open source** and free to use. Incorporation of code that is not published as open source requires the programmer to obtain permission and often purchase the code before integrating it into their program.

---

#### Acknowledgement
{: .no_toc }

Content on this page is adapted from [Runestone Academy - Barb Ericson, Beryl Hoffman, Peter Seibel](https://runestone.academy/ns/books/published/csawesome2/csawesome2.html).
{: .fs-2 }
